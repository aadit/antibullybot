{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import itertools\n",
      "import string\n",
      "from scipy import linalg\n",
      "from sklearn import decomposition"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class CoMatrix:\n",
      "    # Builds co-occurrence matrix.\n",
      "    words_to_i = {}\n",
      "    comat = np.zeros((0,0))   \n",
      "    u = np.zeros((0,0))\n",
      "    s = np.zeros((0,0))\n",
      "    \n",
      "    def reset(self) :\n",
      "        CoMatrix.words_to_i = {}\n",
      "        CoMatrix.comat = np.zeros((0,0))\n",
      "    \n",
      "    def add(self, word_list) :\n",
      "        \"\"\" Given a word_list, which is a list of words, updates the co-occurrence matrix. \"\"\"\n",
      "        # First, count the number of new words to re-shape the matrix.\n",
      "        new_words = [word for word in word_list if word not in CoMatrix.words_to_i]\n",
      "        new_words_count = len(new_words)\n",
      "        \n",
      "        \n",
      "        # Re-shape existing co-occurrence matrix to accommodate new words.\n",
      "        if CoMatrix.comat.shape[0] is 0 :\n",
      "            CoMatrix.comat = np.zeros((new_words_count, new_words_count))\n",
      "        else:\n",
      "            cols = np.zeros((CoMatrix.comat.shape[0], new_words_count))\n",
      "            rows = np.zeros((new_words_count, CoMatrix.comat.shape[1] + new_words_count))\n",
      "            CoMatrix.comat = np.hstack((CoMatrix.comat, cols))\n",
      "            CoMatrix.comat = np.vstack((CoMatrix.comat, rows))\n",
      "        \n",
      "            \n",
      "        # Add new words to the map.\n",
      "        ind = len(CoMatrix.words_to_i)\n",
      "        for word in new_words :\n",
      "            CoMatrix.words_to_i[word] = ind\n",
      "            ind += 1\n",
      "            \n",
      "        # Update the matrix.\n",
      "        word_pairs = itertools.product(word_list, word_list)\n",
      "        for i,j in word_pairs :\n",
      "            CoMatrix.comat[CoMatrix.words_to_i[i], CoMatrix.words_to_i[j]] += 1\n",
      "            \n",
      "            \n",
      "        #print CoMatrix.comat\n",
      "        \n",
      "    def do_svd(self, k) :\n",
      "        \"\"\" Does svd and stores the u and s truncated matrices. k is the number of principal dimensions.\"\"\"\n",
      "        svd = decomposition.TruncatedSVD(n_components=100, n_iterations=5)\n",
      "        CoMatrix.svd_output = svd.fit_transform(CoMatrix.comat)\n",
      "        \n",
      "        #CoMatrix.u,CoMatrix.s,v = linalg.svd(CoMatrix.comat)\n",
      "        #CoMatrix.u = CoMatrix.u[:, 1:]\n",
      "        #CoMatrix.s = CoMatrix.s[1:]\n",
      "        #CoMatrix.u = np.transpose(CoMatrix.u)\n",
      "        #CoMatrix.s = np.diag(CoMatrix.s)\n",
      "        #CoMatrix.u = CoMatrix.u[:, 0:k]\n",
      "        #CoMatrix.s = CoMatrix.s[0:k, 0:k]\n",
      "            \n",
      "    def projection(self, word) :\n",
      "        \"\"\" For a particular word, simply computes the projection by using the word_th row of u and \\\n",
      "        multiplying with s. \"\"\"\n",
      "        if word not in CoMatrix.words_to_i:\n",
      "            print np.zeros((0,0))\n",
      "        else :\n",
      "            return np.dot(CoMatrix.u[CoMatrix.words_to_i[word], :], CoMatrix.s)\n",
      "            \n",
      "    def context_vector(self, word_list) :\n",
      "        \"\"\" Given a word_list, computes the corresponding context vector by summing over all the words. \"\"\"\n",
      "        c_vector = np.zeros((1,k))\n",
      "        for word in word_list :\n",
      "            pr = projection(word)\n",
      "            if pr.shape[0] == 0 :\n",
      "                print \"Error: word not seen before\";\n",
      "            else :\n",
      "                c_vector = np.add(c_vector, pr)\n",
      "        return c_vector\n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def comp_cos(a,b) :\n",
      "    return np.dot(a,b) / ( np.linalg.norm(a) * np.linalg.norm(b))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Testing \"\"\"\n",
      "\"\"\" Check simpel co-occurrence. \"\"\"\n",
      "word_file = \"/usr/share/dict/british-english\"\n",
      "WORDS = open(word_file).read().splitlines()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "no_words = len(WORDS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = CoMatrix()\n",
      "m.reset()\n",
      "for i in range(100) :\n",
      "    wl1 = [random.choice(WORDS) for i in range(10)]\n",
      "    wl1.append('cookies')\n",
      "    wl1.append('biscuits')\n",
      "    #.append('pastries')\n",
      "    wl2 = [random.choice(WORDS) for i in range(10)]\n",
      "    wl2.append('biscuits')\n",
      "    wl2.append('pastries')\n",
      "    m.add(wl1)\n",
      "    #m.add([random.choice(WORDS) for i in range(10)])\n",
      "    m.add(wl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m.comat.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "(1972, 1972)"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m.do_svd(100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vc = m.projection('cookies')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vb = m.projection('biscuits')\n",
      "#vp = m.projection('pastries')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "comp_cos(vc,vb)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for word in m.words_to_i :\n",
      "    if comp_cos(vb, m.projection(word)) > .7 : \n",
      "        print word, comp_cos(vb, m.projection(word))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Wilmington 0.815165861307\n",
        "folly 0.815165861307\n",
        "Advil's 0.815165861307\n",
        "cookies 0.859332626891\n",
        "laryngitis's 0.815165861307\n",
        "Hensley 0.815165861307\n",
        "biscuits 0.999999915469\n",
        "ipecacs 0.815165861307\n",
        "procrastination's 0.815165861307\n",
        "aggregate's 0.815165861307\n",
        "conjures"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.815165861307\n",
        "pastries 0.859105414959\n",
        "Hesse 0.815165861307\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ar= m.comat[m.words_to_i['Hesse']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "idx = np.nonzero(ar)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ar[idx]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "idx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "(array([10, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]),)"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}